{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12180405,"sourceType":"datasetVersion","datasetId":7671409},{"sourceId":437880,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":356170,"modelId":376972}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torchaudio\nimport random\nfrom torch.utils.data import Dataset, DataLoader, Subset\n\npath1 = \"/kaggle/input/dcase2025-evaluation-dataset/Data_part1.npz\"\npath2 = \"/kaggle/input/dcase2025-evaluation-dataset/Data_part2.npz\"\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu' # Device configuration\nprint(f\"Device: {device}\")\n\ndef get_class_name(klass='unknown',getall=False):\n    # Class mappings\n    classes_names = {'airport': 0, 'shopping_mall': 1, 'metro_station': 2, 'street_pedestrian': 3,'public_square': 4, 'street_traffic': 5, 'tram': 6, 'bus': 7, 'metro': 8, 'park': 9}\n    class_indx = {v: k for k, v in classes_names.items()}\n    if getall :\n        return classes_names\n    classes_names = classes_names | class_indx\n    return classes_names.get(klass)\n\ndef get_device_name(dev='unknown',getall=False):\n    # Class mappings\n    devices_names = {'a' : 0,'b' : 1,'c' : 2,'s1': 3,'s2': 4,'s3': 5,'unknown': 6}\n    if getall :\n        return devices_names\n    return devices_names.get(dev) if devices_names.get(dev) != None else 6\n\nclass MelSpecsDataset(Dataset):\n    def __init__(self, data , rec_device='unknown'):\n        self.data = data['mel']  # for version 1 and 2 of the dataset           \n        self.names = data['name']\n        self.devs = self.encode2int_dev(data['device'])  # Loaded as a numpy array\n        \n        mask = np.ones(len(self.names), dtype=bool)  # Initialize mask as all True\n        mask = (data['device'] == rec_device).astype(bool)  # Base mask for rec_device\n        self.data = self.data[mask]\n        self.names = self.names[mask]\n        self.devs = self.devs[mask]\n                 \n    def __getitem__(self, item):\n        log_mel_tensor = torch.tensor(self.data[item], dtype=torch.float32)\n        dev = torch.tensor(self.devs[item])\n        name = self.names[item]  # Include the sample name in the output            \n        return log_mel_tensor.unsqueeze(0), dev, name\n        \n    def __len__(self):\n        return len(self.devs)\n\n    @staticmethod\n    def encode2int_dev(values):\n        return np.array([get_device_name(dev=v) for v in values])\n\ndata1 = np.load(path1)  # Load the .npz file\ndata2 = np.load(path2)  # Load the .npz file\ndevs = ['a','b','c','s1','s2','s3','unknown']\ntest_dataset = {}\ntest_loader = {}\nfor dev in devs:\n    print(\"Data Generator declared\")\n    test_dataset_part1 = MelSpecsDataset(data=data1, rec_device=dev)\n    print(\"Dataset part 1 defined\")\n    test_dataset_part2 = MelSpecsDataset(data=data2, rec_device=dev)\n    print(\"Dataset part 2 defined\")\n    test_dataset[dev] = torch.utils.data.ConcatDataset([test_dataset_part1, test_dataset_part2])\n    print(f\"Test Dataset defined - Number of samples: {len(test_dataset[dev])}\")\n    del test_dataset_part1, test_dataset_part2\n    test_loader[dev] = DataLoader(dataset=test_dataset[dev], batch_size=1024, num_workers=4, shuffle=False, drop_last=False)\n    # test_loader[dev] = DataLoader(dataset=Subset(test_dataset[dev], range(16)), batch_size=2, num_workers=16, shuffle=False, drop_last=False)\n    print(f\"Test Loader defined - Number of batches: {len(test_loader[dev])}\")\n\ndel data1, data2\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-06-27T07:55:31.982457Z","iopub.execute_input":"2025-06-27T07:55:31.982748Z","iopub.status.idle":"2025-06-27T08:05:03.312485Z","shell.execute_reply.started":"2025-06-27T07:55:31.982725Z","shell.execute_reply":"2025-06-27T08:05:03.311808Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Device: cuda:0\nData Generator declared\nDataset part 1 defined\nDataset part 2 defined\nTest Dataset defined - Number of samples: 1\nTest Loader defined - Number of batches: 28\nData Generator declared\nDataset part 1 defined\nDataset part 2 defined\nTest Dataset defined - Number of samples: 2\nTest Loader defined - Number of batches: 19\nData Generator declared\nDataset part 1 defined\nDataset part 2 defined\nTest Dataset defined - Number of samples: 3\nTest Loader defined - Number of batches: 19\nData Generator declared\nDataset part 1 defined\nDataset part 2 defined\nTest Dataset defined - Number of samples: 4\nTest Loader defined - Number of batches: 19\nData Generator declared\nDataset part 1 defined\nDataset part 2 defined\nTest Dataset defined - Number of samples: 5\nTest Loader defined - Number of batches: 19\nData Generator declared\nDataset part 1 defined\nDataset part 2 defined\nTest Dataset defined - Number of samples: 6\nTest Loader defined - Number of batches: 19\nData Generator declared\nDataset part 1 defined\nDataset part 2 defined\nTest Dataset defined - Number of samples: 7\nTest Loader defined - Number of batches: 54\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass RepConv2d(nn.Module):\n    def __init__(self, input_channel, output_channel, stride=(1, 1), groups=1):\n        super().__init__()\n        self.input_channel = input_channel\n        self.output_channel = output_channel\n        self.stride = stride\n\n        # Initial convolutions\n        self.conv1 = nn.Conv2d(input_channel, output_channel, kernel_size=(3, 3),\n                               stride=stride, padding=(1, 1), bias=False,groups=groups)\n        self.conv2 = nn.Conv2d(input_channel, output_channel, kernel_size=(1, 3),\n                               stride=stride, padding=(0, 1), bias=False,groups=groups)\n        self.conv3 = nn.Conv2d(input_channel, output_channel, kernel_size=(3, 1),\n                               stride=stride, padding=(1, 0), bias=False,groups=groups)\n        self.conv4 = nn.Conv2d(input_channel, output_channel, kernel_size=(1, 1),\n                               stride=stride, padding=(0, 0), bias=False,groups=groups)\n\n    def forward(self, x):\n        x1 = self.conv1(x)\n        x2 = self.conv2(x)\n        x3 = self.conv3(x)\n        x4 = self.conv4(x)\n        return x1 + x2 + x3 + x4\n\n    def merge_convs(self):\n        conv2ds_list = [self.conv1, self.conv2, self.conv3, self.conv4]\n        main_shape = conv2ds_list[0].weight.data.shape\n        device = conv2ds_list[0].weight.device  # Get device from one of the convs\n\n        # Initialize zero tensors on the correct device\n        conv1 = conv2ds_list[0].weight.data\n        conv2 = torch.zeros(main_shape, device=device)\n        conv3 = torch.zeros(main_shape, device=device)\n        conv4 = torch.zeros(main_shape, device=device)\n\n        # Fill the corresponding parts\n        conv2[:, :, 1, :] = conv2ds_list[1].weight.data.squeeze(2)\n        conv3[:, :, :, 1] = conv2ds_list[2].weight.data.squeeze(3)\n        conv4[:, :, 1, 1] = conv2ds_list[3].weight.data.squeeze(3).squeeze(2)\n\n        # Create new Conv2d layer on same device\n        conv2d = nn.Conv2d(\n            in_channels=self.conv1.in_channels,\n            out_channels=self.conv1.out_channels,\n            kernel_size=self.conv1.kernel_size,\n            stride=self.conv1.stride,\n            padding=self.conv1.padding,\n            bias=False,\n            groups=self.conv1.groups\n        ).to(device)\n\n        with torch.no_grad():\n            conv2d.weight.copy_((conv1 + conv2 + conv3 + conv4))\n\n        return conv2d\n\n    def get_reparametrized_layer(self):\n        conv2d = self.merge_convs()\n        return nn.Sequential(conv2d)\n\n\nclass ResidualNormalization(nn.Module):\n    \"\"\"\n    Combined normalization layer:\n    Î» * x + InstanceNorm(x)\n    \"\"\"\n    def __init__(self, num_features):\n        super().__init__()\n        # Learnable per-channel scaling factor\n        self.lambda_param = nn.Parameter(torch.ones(num_features, 1, 1))\n        self.instance_norm = nn.InstanceNorm2d(num_features, affine=True)\n\n    def forward(self, x):\n        return self.lambda_param * x + self.instance_norm(x)\n\n\nclass LearnablePooling(nn.Module):\n    \"\"\"\n    Attention-based learnable pooling with Global Average Pooling (GAP)\n    Output: concat(attention_pooled_features, GAP_features)\n    \"\"\"\n    def __init__(self, in_channels, hidden_dim=None):\n        super().__init__()\n        hidden_dim = hidden_dim or in_channels // 2\n        \n        # Input normalization\n        self.bn_input = ResidualNormalization(in_channels)\n        \n        # Attention mechanism\n        self.attn_conv = nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=False)\n        self.bn_attn = ResidualNormalization(hidden_dim)\n        self.attn_score = nn.Conv2d(hidden_dim, in_channels, kernel_size=1, bias=False)\n        self.activation = nn.LeakyReLU(0.1, inplace=True)\n        \n        # Global average pooling\n        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n\n    def forward(self, x):\n        # Input normalization\n        x_norm = self.bn_input(x)\n        \n        # Attention weights calculation\n        attn = self.activation(self.bn_attn(self.attn_conv(x_norm)))\n        scores = self.attn_score(attn)\n        \n        # Softmax over spatial dimensions\n        b, c, h, w = x.size()\n        spatial_weights = F.softmax(scores.view(b, c, -1), dim=-1).view(b, c, h, w)\n        \n        # Attention-weighted pooling\n        attn_pooled = (x * spatial_weights).sum(dim=[2, 3])\n        \n        # Global average pooling\n        gap_pooled = self.global_avg_pool(x).squeeze(-1).squeeze(-1)\n        \n        # Concatenate both pooling results\n        return torch.cat([attn_pooled, gap_pooled], dim=1)\n\n\nclass DSFlexiNetBlock(nn.Module):\n    \"\"\"Inverted Residual Block with Expansion and RepConv\"\"\"\n    def __init__(self, in_channels, out_channels, stride, expansion_factor=6):\n        super().__init__()\n        self.stride = stride\n        self.use_skip = True\n        mid_channels = in_channels * expansion_factor\n        \n        # ---- Input normalization and scaling ----\n        self.input_norm = nn.BatchNorm2d(in_channels)\n        self.input_scaling = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias = False) if self.use_skip else None\n        \n        # ---- Expansion convolution ----\n        self.expand_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias = False)\n        self.expand_norm = nn.BatchNorm2d( out_channels )\n        self.expand_activation = nn.LeakyReLU()\n        \n        # ---- Spatial convolution ----\n        self.spatial_conv = RepConv2d( out_channels , out_channels, stride=stride, groups = out_channels)\n        self.spatial_norm = nn.BatchNorm2d( out_channels )\n        self.spatial_activation = nn.LeakyReLU()\n        \n        # ---- Projection convolution ----\n        # self.project_conv = nn.Conv2d(out_channels , out_channels , kernel_size = 1 , bias = False ,  )\n        # self.project_norm = nn.BatchNorm2d( mid_channels )\n        # self.dropout = nn.Dropout2d( 0.1 )\n\n    def forward(self, x):\n        residual = self.input_scaling(x) if self.use_skip else None\n        \n        # Input normalization\n        out = self.input_norm(x)\n        \n        # Expansion\n        out = self.expand_conv(out)\n        out = self.expand_activation(out)\n        \n        # Spatial processing\n        out = self.spatial_norm(out)\n        out = self.spatial_conv(out)\n        out = self.spatial_activation(out)\n        \n        # Projection\n        # out = self.project_norm(out)\n        # out = self.project_conv(out)\n        # out = self.dropout(out)\n        \n        # Residual connection\n        return out + residual if self.use_skip else out\n\n\nclass DSFlexiNet(nn.Module):\n    \"\"\"Main Network Architecture with RepConv and Flexible Blocks\"\"\"\n    def __init__(self, num_classes=10):\n        super().__init__()\n        # assert len(expansion_factors) == 6, \"Requires 6 expansion factors\"\n        \n        # ---- Initial Convolution Layers ----\n        self.input_norm = nn.BatchNorm2d(1)\n        \n        # Stage 1: Downsample\n        self.conv1 = RepConv2d(1, 16, stride = ( 2 , 2))\n        self.norm1 = nn.BatchNorm2d(16)\n        self.activation1 = nn.ReLU()\n        # Stage 2: Downsample\n        self.conv2 = RepConv2d( 16 , 32 , stride = ( 2 , 2) )\n        self.activation2 = nn.ReLU()\n        \n        # ---- Residual Stages ----\n        # Stage 1: Residual blocks\n        self.stage1 = nn.Sequential(\n            DSFlexiNetBlock(32, 32, stride=(1,1)),\n            DSFlexiNetBlock(32, 32, stride=(1,1)),\n            DSFlexiNetBlock(32, 32, stride=(1,1))\n        )\n        self.stage1_norm = ResidualNormalization(32)\n        \n        # Stage 2: Residual blocks\n        self.stage2 = nn.Sequential(\n            DSFlexiNetBlock(32, 32, stride=(1,1)),\n            DSFlexiNetBlock(32 , 32, stride=(1,1)),\n            DSFlexiNetBlock(32 , 32, stride=(1,1)),\n        )\n        self.stage2_norm = ResidualNormalization(32)\n        \n        # Stage 3: Final residual block\n        self.stage3 = nn.Sequential(\n            DSFlexiNetBlock(32 , 64 , stride=(1,1)),\n        )\n        \n        self.stage3_norm = ResidualNormalization(64)\n        \n        # ---- Classification Head ----\n        self.pooling = LearnablePooling(64)\n        self.head_norm = nn.BatchNorm1d(64 * 2)\n        self.dropout = nn.Dropout(0.2)\n        self.classifier = nn.Linear(64 * 2, num_classes)\n\n    def forward(self, x , device = None):\n        # Input preprocessing\n        if x.dim() == 3:\n            x = x.unsqueeze(1)  # Add channel dimension\n\n        x = self.input_norm(x)\n        # Initial convolution stages\n        x = self.conv1(x)\n        x = self.activation1(x)\n        x = self.norm1(x)\n        x = self.conv2(x)\n        x = self.activation2(x)\n        \n        # Residual stages with skip connections\n        x = self.stage1(x) + x\n        x = self.stage1_norm(x)\n        \n        x = self.stage2(x) + x\n        x = self.stage2_norm(x)\n        \n        x = self.stage3(x)\n        x = self.stage3_norm(x)\n        \n        # Classification head\n        x = self.pooling(x)\n        x = self.head_norm(x)\n        x = self.dropout(x)\n        x = self.classifier(x)\n        return x\n\ndef ReParametrize(module,device):\n    \"\"\"\n    Recursively replaces all RepConv2d layers in a module with their reparametrized version.\n    \"\"\"\n    for name, child in list(module.named_children()):\n        if isinstance(child, RepConv2d):\n            # print(f\"Reparametrizing {name}\")\n            new_module = child.get_reparametrized_layer().to(device)\n            setattr(module, name, new_module)\n        else:\n            ReParametrize(child,device)\n\n\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu' # Device configuration\nprint(f\"Device: {device}\")\n\nmodels_dir = \"/kaggle/input/dcase2025-task1-models/pytorch/final_student_models/2/\"\nsubmission = 1 # 2 , 4\nmodel_names = [\"GLOBAL.pth\", f\"V{submission}-A.pth\", f\"V{submission}-B.pth\", f\"V{submission}-C.pth\", f\"V{submission}-S1.pth\", f\"V{submission}-S2.pth\", f\"V{submission}-S3.pth\"]\n\nmodels = [DSFlexiNet().to(device) for v in model_names]\nfor i in range(len(model_names)):\n    ReParametrize(models[i],device=device)\n    models[i].load_state_dict(torch.load(models_dir+model_names[i], map_location=device)['model_state_dict'])\n    print(f\"Model {model_names[i]} Loaded\")","metadata":{"execution":{"iopub.status.busy":"2025-06-27T08:05:03.313739Z","iopub.execute_input":"2025-06-27T08:05:03.314109Z","iopub.status.idle":"2025-06-27T08:05:04.320127Z","shell.execute_reply.started":"2025-06-27T08:05:03.314090Z","shell.execute_reply":"2025-06-27T08:05:04.319535Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Device: cuda:0\nModel GLOBAL.pth Loaded\nModel V1-A.pth Loaded\nModel V1-B.pth Loaded\nModel V1-C.pth Loaded\nModel V1-S1.pth Loaded\nModel V1-S2.pth Loaded\nModel V1-S3.pth Loaded\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport torch.nn.functional as F\n\n# Define the device types and their corresponding model indices\ndevice_types = ['a', 'b' , 'c', 's1', 's2', 's3', 'unknown']\nmodel_mapping = {\n    'a': 1,      # V1-A.pth\n    'b': 2,      # V1-B.pth\n    'c': 3,      # V1-C.pth\n    's1': 4,     # V1-S1.pth\n    's2': 5,     # V1-S2.pth\n    's3': 6,     # V1-S3.pth\n    'unknown': 0 # GLOBAL.pth\n}\n\n# Class names in the order required by the submission template\nclass_names = ['airport', 'shopping_mall', 'metro_station', 'street_pedestrian','public_square', 'street_traffic', 'tram', 'bus', 'metro', 'park']\n\n# Function to evaluate a model on a data loader and return predictions with probabilities\ndef evaluate_test_dataset(model, loader, device):\n    model.eval()\n    results = {\n        'filename': [],\n        'scene_label': [],\n        **{class_name: [] for class_name in class_names}\n    }\n    with torch.no_grad():\n        for batch in loader:\n            mels, devices, names = batch\n            mels = mels.to(device)\n            outputs = model(mels)\n            # Apply softmax to get probabilities\n            probs = F.softmax(outputs, dim=1).cpu().numpy()\n            # Get predicted class indices\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n            # Convert class indices to class names\n            predicted_labels = [get_class_name(klass=pred) for pred in preds]\n            # Collect results\n            results['filename'].extend(names)\n            results['scene_label'].extend(predicted_labels)\n            # Add probabilities for each class\n            for i, class_name in enumerate(class_names):\n                results[class_name].extend(probs[:, i])\n    return results\n\n# Collect predictions for all device types\nall_results = {\n    'filename': [],\n    'scene_label': [],\n    **{class_name: [] for class_name in class_names}\n}\nfor dev in device_types:\n    print(f\"Evaluating model for device: {dev}\")\n    model_idx = model_mapping[dev]\n    model = models[model_idx]\n    loader = test_loader[dev]\n    # Evaluate the model\n    results = evaluate_test_dataset(model, loader, device)\n    # Aggregate results\n    all_results['filename'].extend(results['filename'])\n    all_results['scene_label'].extend(results['scene_label'])\n    for class_name in class_names:\n        all_results[class_name].extend(results[class_name])\n\n# Create a DataFrame for submission\nsubmission_df = pd.DataFrame(all_results)\n# Ensure filenames have '.wav' extension\nsubmission_df['filename'] = submission_df['filename'].apply(lambda x: f\"{x}.wav\")\n# Sort by filename to ensure consistent ordering\nsubmission_df = submission_df.sort_values(by='filename')\n# Reorder columns to match the template\nsubmission_columns = ['filename', 'scene_label'] + class_names\nsubmission_df = submission_df[submission_columns]\n# Save to CSV\nsubmission_df.to_csv('temp.csv', index=False)\nprint(\"Submission file created: dcase2025_task1_submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T08:16:59.179900Z","iopub.execute_input":"2025-06-27T08:16:59.180570Z","iopub.status.idle":"2025-06-27T08:17:29.648485Z","shell.execute_reply.started":"2025-06-27T08:16:59.180542Z","shell.execute_reply":"2025-06-27T08:17:29.647779Z"}},"outputs":[{"name":"stdout","text":"Evaluating model for device: a\nEvaluating model for device: b\nEvaluating model for device: c\nEvaluating model for device: s1\nEvaluating model for device: s2\nEvaluating model for device: s3\nEvaluating model for device: unknown\nSubmission file created: dcase2025_task1_submission.csv\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\n\n# Step 1: Read the CSV file into a DataFrame\ndf = pd.read_csv('output.csv')\n\n# Step 2: Reorder the columns (replace ['col1', 'col2', ...] with your desired column order)\n# Example:\ndesired_column_order = ['filename', 'scene_label', 'airport', 'bus', 'metro', 'metro_station', 'park', 'public_square', 'shopping_mall', 'street_pedestrian', 'street_traffic', 'tram']\ndf = df[desired_column_order]\n\n# Step 3: Round all numerical values to 4 decimal places\ndf = df.round(4)\n\n# Step 4: Save the modified DataFrame to a tab-separated CSV file\ndf.to_csv('output.csv', sep='\\t', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T08:21:13.673476Z","iopub.execute_input":"2025-06-27T08:21:13.673794Z","iopub.status.idle":"2025-06-27T08:21:15.392536Z","shell.execute_reply.started":"2025-06-27T08:21:13.673763Z","shell.execute_reply":"2025-06-27T08:21:15.391736Z"}},"outputs":[],"execution_count":10}]}